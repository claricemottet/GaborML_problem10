{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gabor ML - Problem 10\n",
    "\n",
    "Outline:\n",
    "\n",
    "Functions:\n",
    "-Generate linearly separably data\n",
    "-Generate non-linearly separably data\n",
    "-Perceptron algorithm\n",
    "\n",
    "Uses:\n",
    "-test algorithm on different dimensions of data and types of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "path_out_ = r'/home/clarice/Documents/VSCode/Term2_Gabor_ML/homework3/GaborML_problem10/outputs'\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "\n",
    "#Generate linearly separable data\n",
    "def generate_ls_data(a, d, n):\n",
    "    #a is a number in range [0,1]\n",
    "    #d is dimension of sample data\n",
    "    #n is number of sample points\n",
    "\n",
    "    #x is a list of n numpy arrays\n",
    "    #y is a list of n corresponding {-1,1}\n",
    "\n",
    "    #determine y values with probability .5\n",
    "    probability_y_equals_1 = .5\n",
    "    y = [1 if random.random() > probability_y_equals_1 else -1 for _ in range(n)]\n",
    "    x = []\n",
    "\n",
    "    #creates list of x iid sample vectors based on problem conditions\n",
    "    for i in range(n):\n",
    "        x_i = np.zeros(d)\n",
    "        for j in range(d):\n",
    "            #first element based on a\n",
    "            if j == 0:\n",
    "                if y[i] == 1:\n",
    "                    x_i[j] = random.uniform(-1,-a)\n",
    "                else:\n",
    "                    x_i[j] = random.uniform(a,1)\n",
    "            #other elements based on [-1,1]\n",
    "            else:\n",
    "                x_i[j] = random.uniform(-1,1)\n",
    "        x.append(x_i)        \n",
    "\n",
    "    return x, y\n",
    "\n",
    "def generate_nls_data(m, d, n):\n",
    "    #create y data\n",
    "    probability_y_equals_1 = .5\n",
    "    y = [1 if random.random() >= probability_y_equals_1 else -1 for _ in range(n)]\n",
    "\n",
    "    #create non-linearly separable data per problem description\n",
    "    mean = np.zeros(d)\n",
    "    mean[0] = m\n",
    "    cov = np.identity(d)\n",
    "    \n",
    "    x_arr = np.random.multivariate_normal(mean, cov, n)\n",
    "    x = [x_arr[i] for i in range(n)]\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def perceptron_algorithm(x, y, learning_rate, max_epochs):\n",
    "    #dimension requirements\n",
    "    d = int(x[0].size)\n",
    "    n = len(y)\n",
    "\n",
    "    convergence_ind = 0\n",
    "    steps_to_converge = max_epochs\n",
    "    #random values between 0 and 1 (uniform)\n",
    "    w = np.random.rand(d)\n",
    "    b = 0.0\n",
    "\n",
    "    #function vars\n",
    "    update_log = np.zeros(max_epochs)\n",
    "    num_epochs_taken = 0\n",
    "    num_updates_per_epoch = 0\n",
    "\n",
    "    while num_epochs_taken < max_epochs:\n",
    "        for i in range(n):\n",
    "            y_pred = np.sign(np.dot(w,x[i])+b)\n",
    "            if y_pred != y[i]:\n",
    "                w = np.add(w, learning_rate*(y[i]-y_pred)*x[i])\n",
    "                b = b + learning_rate*(y[i]-y_pred)\n",
    "                num_updates_per_epoch += 1\n",
    "        #update vars for next epoch\n",
    "        update_log[num_epochs_taken] = num_updates_per_epoch\n",
    "        num_epochs_taken += 1\n",
    "        num_updates_per_epoch = 0\n",
    "\n",
    "        #check for convergence\n",
    "        if update_log[num_epochs_taken-1] == 0:\n",
    "            steps_to_converge = num_epochs_taken\n",
    "            num_epochs_taken = max_epochs\n",
    "            convergence_ind = 1\n",
    "\n",
    "    return w, b, update_log, steps_to_converge, convergence_ind\n",
    "\n",
    "def perceptron_algorithm_accuracy(x_test, y_test, w, b):\n",
    "    n = len(y_test)\n",
    "    error_count = 0\n",
    "    for i in range(n):\n",
    "        y_pred = np.sign(np.dot(w,x_test[i])+b)\n",
    "        if y_test[i] != y_pred:\n",
    "            error_count += 1\n",
    "\n",
    "    error_rate = error_count/n\n",
    "\n",
    "    return error_count, error_rate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep track of linearly separable data\n",
    "df_log_ls = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linearly separable case\n",
    "\n",
    "a_values = [.0001, .001, .01, .1, .2]\n",
    "d_values = [2, 100, 250, 500, 1000]\n",
    "n_values = [20, 100, 1000, 5000, 7500]\n",
    "\n",
    "learning_rate = .1\n",
    "max_epochs = 200\n",
    "\n",
    "num_of_simulations = 20\n",
    "\n",
    "#create a log of testing different values\n",
    "for iter_ in range(num_of_simulations):\n",
    "    for a in a_values:\n",
    "        for d in d_values:\n",
    "            for n in n_values:\n",
    "                x, y = generate_ls_data(a, d, n)\n",
    "                w, b, update_log, steps_to_converge, convergence_ind = perceptron_algorithm(x, y, learning_rate, max_epochs)\n",
    "                x_test, y_test = generate_ls_data(a, d, n)\n",
    "                error_count, error_rate = perceptron_algorithm_accuracy(x_test, y_test, w, b)\n",
    "                df_ = pd.DataFrame([[iter_, a, d, n, steps_to_converge, convergence_ind, error_rate]], columns = ['simulation_run','a_value','d_value','n_value','steps_to_converge','convergence_ind','error_rate'])\n",
    "                df_log_ls = pd.concat([df_log_ls,df_], ignore_index = False)\n",
    "                df_log_ls.reset_index(drop = True, inplace = True)\n",
    "                df_log_ls.to_excel(path_out_+'//'+'df_log_linearly_separable.xlsx',index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create log of non-linearly separable data\n",
    "df_log_nls = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-linearly separable case\n",
    "\n",
    "m_values = [0, 2, 4]\n",
    "d_values = [2, 100, 250, 500, 1000]\n",
    "n_values = [20, 100, 1000, 5000, 7500]\n",
    "\n",
    "learning_rate = .1\n",
    "max_epochs = 100\n",
    "\n",
    "num_of_simulations = 20\n",
    "\n",
    "#create a log of testing different values\n",
    "for iter_ in range(num_of_simulations):\n",
    "    for m in m_values:\n",
    "        for d in d_values:\n",
    "            for n in n_values:\n",
    "                x, y = generate_nls_data(m, d, n)\n",
    "                w, b, update_log, steps_to_converge, convergence_ind = perceptron_algorithm(x, y, learning_rate, max_epochs)\n",
    "                error_count, error_rate = perceptron_algorithm_accuracy(x, y, w, b)\n",
    "                df_ = pd.DataFrame([[iter_, m, d, n, steps_to_converge, convergence_ind, error_rate]], columns = ['simulation_run','m_value','d_value','n_value','steps_to_converge','convergence_ind','error_rate'])\n",
    "                df_log_nls = pd.concat([df_log_nls,df_], ignore_index = False)\n",
    "                df_log_nls.reset_index(drop = True, inplace = True)\n",
    "                df_log_nls.to_excel(path_out_+'//'+'df_log_nonlinearly_separable.xlsx',index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence indicator 0\n",
      "steps to converge 100\n",
      "error rate 0.41933333333333334\n"
     ]
    }
   ],
   "source": [
    "#Non-linearly separable case\n",
    "\n",
    "m = 2 #or another value greater than 0\n",
    "d = 1000\n",
    "n = 7500\n",
    "\n",
    "x, y = generate_nls_data(m, d, n)\n",
    "# print(\"x\",x)\n",
    "# print(\"y\",y)\n",
    "\n",
    "learning_rate = .1\n",
    "max_epochs = 100\n",
    "\n",
    "w, b, update_log, steps_to_converge, convergence_ind = perceptron_algorithm(x, y, learning_rate, max_epochs)\n",
    "\n",
    "print(\"convergence indicator\",convergence_ind)\n",
    "print(\"steps to converge\",steps_to_converge)\n",
    "\n",
    "# print(\"w\",w)\n",
    "# print(\"b\",b)\n",
    "\n",
    "error_count, error_rate = perceptron_algorithm_accuracy(x, y, w, b)\n",
    "\n",
    "print(\"error rate\",error_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
